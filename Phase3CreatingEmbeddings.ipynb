{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9613323,
          "sourceType": "datasetVersion",
          "datasetId": 5866224
        }
      ],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebook5129ef22b4",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tpavan03/Phishing-Detection/blob/main/Phase3CreatingEmbeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas scikit-learn sentence-transformers transformers tensorflow tensorflow-hub gensim torch xgboost openai==0.28.0 tqdm"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:00:21.347501Z",
          "iopub.execute_input": "2024-10-13T14:00:21.347825Z",
          "iopub.status.idle": "2024-10-13T14:00:33.967721Z",
          "shell.execute_reply.started": "2024-10-13T14:00:21.347792Z",
          "shell.execute_reply": "2024-10-13T14:00:33.966683Z"
        },
        "trusted": true,
        "id": "VWXms5H8BvGy",
        "outputId": "8a5e3a95-e749-49f8-d37e-2102e28dc386"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (3.2.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.16.1)\nRequirement already satisfied: tensorflow-hub in /opt/conda/lib/python3.10/site-packages (0.16.1)\nRequirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (4.3.3)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: xgboost in /opt/conda/lib/python3.10/site-packages (2.0.3)\nRequirement already satisfied: openai==0.28.0 in /opt/conda/lib/python3.10/site-packages (0.28.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\nRequirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.10/site-packages (from openai==0.28.0) (2.32.3)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from openai==0.28.0) (3.9.5)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.25.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.3.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.62.2)\nRequirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.16.2)\nRequirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: tf-keras>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-hub) (2.16.0)\nRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim) (7.0.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai==0.28.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai==0.28.0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai==0.28.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai==0.28.0) (2024.8.30)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.28.0) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.28.0) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.28.0) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.28.0) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.28.0) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.28.0) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# For embeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import BertTokenizer, BertModel, RobertaTokenizer, RobertaModel, AlbertTokenizer, AlbertModel, TFBertForSequenceClassification\n",
        "import tensorflow_hub as hub\n",
        "import openai\n",
        "import gensim\n",
        "import torch\n",
        "\n",
        "# For Neural Networks\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Bidirectional, Embedding, Flatten"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:00:33.969189Z",
          "iopub.execute_input": "2024-10-13T14:00:33.969564Z",
          "iopub.status.idle": "2024-10-13T14:00:33.978821Z",
          "shell.execute_reply.started": "2024-10-13T14:00:33.969526Z",
          "shell.execute_reply": "2024-10-13T14:00:33.977826Z"
        },
        "trusted": true,
        "id": "yXjqMgnaBvGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/kaggle/input/pavans/pavan.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:00:33.980377Z",
          "iopub.execute_input": "2024-10-13T14:00:33.981043Z",
          "iopub.status.idle": "2024-10-13T14:00:35.754372Z",
          "shell.execute_reply.started": "2024-10-13T14:00:33.981007Z",
          "shell.execute_reply": "2024-10-13T14:00:35.753289Z"
        },
        "trusted": true,
        "id": "qqwr6L1tBvGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_total = df.drop(['FILENAME', 'Domain', 'TLD', 'Title', 'label'], axis=1)\n",
        "y = df['label'].values"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:00:35.757397Z",
          "iopub.execute_input": "2024-10-13T14:00:35.757719Z",
          "iopub.status.idle": "2024-10-13T14:00:35.789568Z",
          "shell.execute_reply.started": "2024-10-13T14:00:35.757686Z",
          "shell.execute_reply": "2024-10-13T14:00:35.788314Z"
        },
        "trusted": true,
        "id": "vs4gaoD2BvG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:00:35.790853Z",
          "iopub.execute_input": "2024-10-13T14:00:35.791186Z",
          "iopub.status.idle": "2024-10-13T14:00:35.797777Z",
          "shell.execute_reply.started": "2024-10-13T14:00:35.791152Z",
          "shell.execute_reply": "2024-10-13T14:00:35.796811Z"
        },
        "trusted": true,
        "id": "izoRt6ThBvG0",
        "outputId": "e897c84d-45d0-4118-c45a-3534ba397762"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(235795, 56)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_total, X_test_total, y_train, y_test = train_test_split(X_total, y, test_size=0.2, random_state=42, stratify=y)\n",
        "# Separate 'URL' from other features in training set\n",
        "X_train = X_train_total['URL'].values\n",
        "X_train_manual = X_train_total.drop('URL', axis=1).values\n",
        "\n",
        "# Separate 'URL' from other features in testing set\n",
        "X_test = X_test_total['URL'].values\n",
        "X_test_manual = X_test_total.drop('URL', axis=1).values# Separate 'URL' from other features in training set\n",
        "X_train = X_train_total['URL'].values\n",
        "X_train_manual = X_train_total.drop('URL', axis=1).values"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:00:35.799041Z",
          "iopub.execute_input": "2024-10-13T14:00:35.799379Z",
          "iopub.status.idle": "2024-10-13T14:00:36.093756Z",
          "shell.execute_reply.started": "2024-10-13T14:00:35.799307Z",
          "shell.execute_reply": "2024-10-13T14:00:36.092846Z"
        },
        "trusted": true,
        "id": "7y3e3dAUBvG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit scaler on training manual features and transform both training and testing manual features\n",
        "X_train_manual_scaled = scaler.fit_transform(X_train_manual)\n",
        "X_test_manual_scaled = scaler.transform(X_test_manual)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:00:36.095227Z",
          "iopub.execute_input": "2024-10-13T14:00:36.095716Z",
          "iopub.status.idle": "2024-10-13T14:00:36.166771Z",
          "shell.execute_reply.started": "2024-10-13T14:00:36.095669Z",
          "shell.execute_reply": "2024-10-13T14:00:36.165807Z"
        },
        "trusted": true,
        "id": "WtidbEXUBvG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the manual features using pickle\n",
        "with open('X_train_manual_scaled.pkl', 'wb') as f:\n",
        "  pickle.dump(X_train_manual_scaled,f)\n",
        "\n",
        "with open('X_test_manual_scaled.pkl', 'wb') as f:\n",
        "  pickle.dump(X_test_manual_scaled,f)\n",
        "with open('y_train.pkl', 'wb') as f:\n",
        "  pickle.dump(y_train,f)\n",
        "\n",
        "with open('y_test.pkl', 'wb') as f:\n",
        "  pickle.dump(y_test,f)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:00:36.167931Z",
          "iopub.execute_input": "2024-10-13T14:00:36.168258Z",
          "iopub.status.idle": "2024-10-13T14:00:36.385688Z",
          "shell.execute_reply.started": "2024-10-13T14:00:36.168224Z",
          "shell.execute_reply": "2024-10-13T14:00:36.384626Z"
        },
        "trusted": true,
        "id": "qORLKHBrBvG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sbert_embeddings(texts):\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    embeddings = model.encode(texts, batch_size=32, show_progress_bar=True)\n",
        "    return embeddings"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:00:36.387154Z",
          "iopub.execute_input": "2024-10-13T14:00:36.387587Z",
          "iopub.status.idle": "2024-10-13T14:00:36.393142Z",
          "shell.execute_reply.started": "2024-10-13T14:00:36.387533Z",
          "shell.execute_reply": "2024-10-13T14:00:36.392104Z"
        },
        "trusted": true,
        "id": "MgsgoJRhBvG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bert_cls_embeddings(texts, batch_size=64, max_length=128, model_name='bert-base-uncased', device='cuda'):\n",
        "    # Convert NumPy array to list if necessary\n",
        "    if isinstance(texts, np.ndarray):\n",
        "        texts = texts.tolist()\n",
        "    elif not isinstance(texts, list):\n",
        "        texts = list(texts)\n",
        "\n",
        "    # Ensure all elements are strings, replace non-strings with empty strings\n",
        "    texts = [str(text) if isinstance(text, str) else \"\" for text in texts]\n",
        "    # Initialize tokenizer and model\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "    model = BertModel.from_pretrained(model_name)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    embeddings = []\n",
        "\n",
        "    # Disable gradient calculation for inference\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"BERT CLS Embeddings\"):\n",
        "            batch_texts = texts[i:i + batch_size]\n",
        "            # Tokenize the batch\n",
        "            inputs = tokenizer(batch_texts,\n",
        "                               padding=True,\n",
        "                               truncation=True,\n",
        "                               max_length=max_length,\n",
        "                               return_tensors='pt')\n",
        "            # Move inputs to the specified device\n",
        "            inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "            # Forward pass\n",
        "            outputs = model(**inputs)\n",
        "            # Extract CLS token embeddings\n",
        "            cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            embeddings.append(cls_embeddings)\n",
        "\n",
        "    # Concatenate all embeddings\n",
        "    embeddings = np.vstack(embeddings)\n",
        "    return embeddings\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:00:36.394179Z",
          "iopub.execute_input": "2024-10-13T14:00:36.394505Z",
          "iopub.status.idle": "2024-10-13T14:00:36.405698Z",
          "shell.execute_reply.started": "2024-10-13T14:00:36.394473Z",
          "shell.execute_reply": "2024-10-13T14:00:36.404652Z"
        },
        "trusted": true,
        "id": "V8CQxMo_BvG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_use_embeddings(texts, batch_size=32):\n",
        "    use_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "    embeddings = []\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"USE Embeddings\", unit=\"batch\"):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        batch_embeddings = use_model(batch_texts).numpy()\n",
        "        embeddings.extend(batch_embeddings)\n",
        "    return np.array(embeddings)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:00:36.406836Z",
          "iopub.execute_input": "2024-10-13T14:00:36.40714Z",
          "iopub.status.idle": "2024-10-13T14:00:36.4189Z",
          "shell.execute_reply.started": "2024-10-13T14:00:36.407108Z",
          "shell.execute_reply": "2024-10-13T14:00:36.417949Z"
        },
        "trusted": true,
        "id": "QY5kO3mBBvG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def get_openai_embeddings(texts, api_key, batch_size=100):\n",
        "\n",
        "    openai.api_key = api_key\n",
        "    embeddings = []\n",
        "\n",
        "    # Process texts in batches\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"OpenAI Embeddings\"):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        try:\n",
        "            response = openai.Embedding.create(input=batch_texts, model=\"text-embedding-ada-002\")\n",
        "            batch_embeddings = [item['embedding'] for item in response['data']]\n",
        "            embeddings.extend(batch_embeddings)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing batch {i // batch_size}: {e}\")\n",
        "            # Optionally, handle retries or skip the batch\n",
        "            continue\n",
        "\n",
        "    return np.array(embeddings)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:00:36.419974Z",
          "iopub.execute_input": "2024-10-13T14:00:36.42025Z",
          "iopub.status.idle": "2024-10-13T14:00:36.429753Z",
          "shell.execute_reply.started": "2024-10-13T14:00:36.420221Z",
          "shell.execute_reply": "2024-10-13T14:00:36.428838Z"
        },
        "trusted": true,
        "id": "Dpyf6FODBvG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.utils import simple_preprocess\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import gensim.downloader as api\n",
        "\n",
        "def get_fasttext_embeddings(texts):\n",
        "    \"\"\"\n",
        "    Generates FastText embeddings for a list of texts by averaging word vectors.\n",
        "\n",
        "    Args:\n",
        "        texts (List[str]): List of input texts.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Array of sentence embeddings.\n",
        "    \"\"\"\n",
        "    # Load FastText KeyedVectors model\n",
        "    print(\"Loading FastText model...\")\n",
        "    model = api.load('fasttext-wiki-news-subwords-300')  # 300-dimensional embeddings\n",
        "\n",
        "    embeddings = []\n",
        "    vector_size = model.vector_size  # Typically 300\n",
        "\n",
        "    for text in tqdm(texts, desc=\"FastText Embeddings\", unit=\"url\"):\n",
        "        # Preprocess the text: tokenize, lowercase, remove punctuation\n",
        "        tokens = simple_preprocess(text)\n",
        "\n",
        "        if tokens:\n",
        "            # Retrieve word vectors for tokens present in the model's vocabulary\n",
        "            word_vectors = [model.get_vector(token) for token in tokens if token in model]\n",
        "\n",
        "            if word_vectors:\n",
        "                # Compute the mean of word vectors to get the sentence embedding\n",
        "                sentence_vector = np.mean(word_vectors, axis=0)\n",
        "            else:\n",
        "                # If no tokens are found in the vocabulary, use a zero vector\n",
        "                sentence_vector = np.zeros(vector_size)\n",
        "        else:\n",
        "            # If text is empty or only contains non-alphanumeric characters, use a zero vector\n",
        "            sentence_vector = np.zeros(vector_size)\n",
        "\n",
        "        embeddings.append(sentence_vector)\n",
        "\n",
        "    return np.array(embeddings)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:00:36.434203Z",
          "iopub.execute_input": "2024-10-13T14:00:36.434837Z",
          "iopub.status.idle": "2024-10-13T14:00:36.443724Z",
          "shell.execute_reply.started": "2024-10-13T14:00:36.43479Z",
          "shell.execute_reply": "2024-10-13T14:00:36.442853Z"
        },
        "trusted": true,
        "id": "wvQ1ZjhCBvG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_roberta_embeddings(texts, batch_size=32, max_length=128, model_name='roberta-base', device='cuda'):\n",
        "    if isinstance(texts, np.ndarray):\n",
        "        texts = texts.tolist()\n",
        "    elif not isinstance(texts, list):\n",
        "        texts = list(texts)\n",
        "\n",
        "    # Ensure all elements are strings, replace non-strings with empty strings\n",
        "    texts = [str(text) if isinstance(text, str) else \"\" for text in texts]\n",
        "    # Initialize tokenizer and model\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "    model = RobertaModel.from_pretrained(model_name)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    embeddings = []\n",
        "\n",
        "    # Disable gradient calculation for inference\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"RoBERTa Embeddings\"):\n",
        "            batch_texts = texts[i:i + batch_size]\n",
        "            # Tokenize the batch\n",
        "            inputs = tokenizer(batch_texts,\n",
        "                               padding=True,\n",
        "                               truncation=True,\n",
        "                               max_length=max_length,\n",
        "                               return_tensors='pt')\n",
        "            # Move inputs to the specified device\n",
        "            inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "            # Forward pass\n",
        "            outputs = model(**inputs)\n",
        "            # Extract CLS token embeddings\n",
        "            cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            embeddings.append(cls_embeddings)\n",
        "\n",
        "    # Concatenate all embeddings\n",
        "    embeddings = np.vstack(embeddings)\n",
        "    return embeddings"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:00:36.444916Z",
          "iopub.execute_input": "2024-10-13T14:00:36.44545Z",
          "iopub.status.idle": "2024-10-13T14:00:36.458453Z",
          "shell.execute_reply.started": "2024-10-13T14:00:36.445409Z",
          "shell.execute_reply": "2024-10-13T14:00:36.457391Z"
        },
        "trusted": true,
        "id": "gZKkvyujBvG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_roberta_embeddings(texts, batch_size=32, max_length=128, model_name='roberta-base', device='cuda'):\n",
        "    if isinstance(texts, np.ndarray):\n",
        "        texts = texts.tolist()\n",
        "    elif not isinstance(texts, list):\n",
        "        texts = list(texts)\n",
        "\n",
        "    # Ensure all elements are strings, replace non-strings with empty strings\n",
        "    texts = [str(text) if isinstance(text, str) else \"\" for text in texts]\n",
        "    # Initialize tokenizer and model\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "    model = RobertaModel.from_pretrained(model_name)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    embeddings = []\n",
        "\n",
        "    # Disable gradient calculation for inference\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"RoBERTa Embeddings\"):\n",
        "            batch_texts = texts[i:i + batch_size]\n",
        "            # Tokenize the batch\n",
        "            inputs = tokenizer(batch_texts,\n",
        "                               padding=True,\n",
        "                               truncation=True,\n",
        "                               max_length=max_length,\n",
        "                               return_tensors='pt')\n",
        "            # Move inputs to the specified device\n",
        "            inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "            # Forward pass\n",
        "            outputs = model(**inputs)\n",
        "            # Extract CLS token embeddings\n",
        "            cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            embeddings.append(cls_embeddings)\n",
        "\n",
        "    # Concatenate all embeddings\n",
        "    embeddings = np.vstack(embeddings)\n",
        "    return embeddings"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:00:36.459627Z",
          "iopub.execute_input": "2024-10-13T14:00:36.460009Z",
          "iopub.status.idle": "2024-10-13T14:00:36.473863Z",
          "shell.execute_reply.started": "2024-10-13T14:00:36.459964Z",
          "shell.execute_reply": "2024-10-13T14:00:36.472873Z"
        },
        "trusted": true,
        "id": "s0e2QnDdBvG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_albert_embeddings(texts, batch_size=32, max_length=128, model_name='albert-base-v2', device='cuda'):\n",
        "    if isinstance(texts, np.ndarray):\n",
        "        texts = texts.tolist()\n",
        "    elif not isinstance(texts, list):\n",
        "        texts = list(texts)\n",
        "\n",
        "    # Ensure all elements are strings, replace non-strings with empty strings\n",
        "    texts = [str(text) if isinstance(text, str) else \"\" for text in texts]\n",
        "    # Initialize tokenizer and model\n",
        "    tokenizer = AlbertTokenizer.from_pretrained(model_name)\n",
        "    model = AlbertModel.from_pretrained(model_name)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    embeddings = []\n",
        "\n",
        "    # Disable gradient calculation for inference\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"ALBERT Embeddings\"):\n",
        "            batch_texts = texts[i:i + batch_size]\n",
        "            # Tokenize the batch\n",
        "            inputs = tokenizer(batch_texts,\n",
        "                               padding=True,\n",
        "                               truncation=True,\n",
        "                               max_length=max_length,\n",
        "                               return_tensors='pt')\n",
        "            # Move inputs to the specified device\n",
        "            inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "            # Forward pass\n",
        "            outputs = model(**inputs)\n",
        "            # Extract CLS token embeddings\n",
        "            cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            embeddings.append(cls_embeddings)\n",
        "\n",
        "    # Concatenate all embeddings\n",
        "    embeddings = np.vstack(embeddings)\n",
        "    return embeddings"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:00:36.475058Z",
          "iopub.execute_input": "2024-10-13T14:00:36.47534Z",
          "iopub.status.idle": "2024-10-13T14:00:36.487942Z",
          "shell.execute_reply.started": "2024-10-13T14:00:36.475303Z",
          "shell.execute_reply": "2024-10-13T14:00:36.487077Z"
        },
        "trusted": true,
        "id": "vSe4mdp6BvG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_dict = {}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:00:36.489078Z",
          "iopub.execute_input": "2024-10-13T14:00:36.489545Z",
          "iopub.status.idle": "2024-10-13T14:00:36.502009Z",
          "shell.execute_reply.started": "2024-10-13T14:00:36.489504Z",
          "shell.execute_reply": "2024-10-13T14:00:36.501195Z"
        },
        "trusted": true,
        "id": "AMGvCHqUBvG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generating SBERT embeddings...\")\n",
        "embeddings_dict['SBERT'] = get_sbert_embeddings(X_train)\n",
        "embeddings_dict['SBERT'].shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:00:36.503145Z",
          "iopub.execute_input": "2024-10-13T14:00:36.503569Z",
          "iopub.status.idle": "2024-10-13T14:01:33.746589Z",
          "shell.execute_reply.started": "2024-10-13T14:00:36.503503Z",
          "shell.execute_reply": "2024-10-13T14:01:33.745451Z"
        },
        "trusted": true,
        "id": "IPpom-YnBvG3",
        "outputId": "37888945-9057-4b8b-b202-6a2411dbf679",
        "colab": {
          "referenced_widgets": [
            "b46866e9b1e74860986b38c23bd2e150",
            "17a41d4de84e4355ad1b131ae48c6177",
            "a47a738b39d7400aa3008827387d1d1f",
            "e0921b2265ba4580ab90ccb1d59f2fc5",
            "1aecdde71f9b4a709676d23c9f19712e",
            "97810c51b1e64207bf93292afb86a50b",
            "8917c1aec3c54b7ca6446c09adeddfe2",
            "a3af8abf69a5475fa4c751df23b34e32",
            "1a33903f42bb4a518e5613685e5e58f1",
            "e735e34edbbf4bf696fa5f2032e352bd",
            "9b339c12daef455c854e026c5078f382",
            "4cf636359e184549a1a53dda7306fa30"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Generating SBERT embeddings...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b46866e9b1e74860986b38c23bd2e150"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17a41d4de84e4355ad1b131ae48c6177"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a47a738b39d7400aa3008827387d1d1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0921b2265ba4580ab90ccb1d59f2fc5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1aecdde71f9b4a709676d23c9f19712e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97810c51b1e64207bf93292afb86a50b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8917c1aec3c54b7ca6446c09adeddfe2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3af8abf69a5475fa4c751df23b34e32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a33903f42bb4a518e5613685e5e58f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e735e34edbbf4bf696fa5f2032e352bd"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b339c12daef455c854e026c5078f382"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/5895 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cf636359e184549a1a53dda7306fa30"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(188636, 384)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generating BERT CLS embeddings...\")\n",
        "embeddings_dict['BERT_CLS'] = get_bert_cls_embeddings(X_train)\n",
        "embeddings_dict['BERT_CLS'].shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:01:33.748Z",
          "iopub.execute_input": "2024-10-13T14:01:33.748377Z",
          "iopub.status.idle": "2024-10-13T14:10:31.560139Z",
          "shell.execute_reply.started": "2024-10-13T14:01:33.74832Z",
          "shell.execute_reply": "2024-10-13T14:10:31.559097Z"
        },
        "trusted": true,
        "id": "Ip4Lfab_BvG4",
        "outputId": "c28b33ff-2bb1-40a0-b70a-dbbd0f7e45e3",
        "colab": {
          "referenced_widgets": [
            "1421b595542b46d3991e70973da94d37",
            "2c6ddb9455d74d8bb42b3d3411b3767a",
            "438ccbfb9a774f2ca4dff98de76abefe",
            "ce4f7917a0d94d1c95a56911bfc0d125",
            "44941ac88ce54ea3b3bf785d2369b294"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Generating BERT CLS embeddings...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1421b595542b46d3991e70973da94d37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c6ddb9455d74d8bb42b3d3411b3767a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "438ccbfb9a774f2ca4dff98de76abefe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce4f7917a0d94d1c95a56911bfc0d125"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44941ac88ce54ea3b3bf785d2369b294"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "BERT CLS Embeddings: 100%|██████████| 2948/2948 [08:54<00:00,  5.51it/s]\n",
          "output_type": "stream"
        },
        {
          "execution_count": 38,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(188636, 768)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generating USE embeddings...\")\n",
        "embeddings_dict['USE'] = get_use_embeddings(X_train)\n",
        "embeddings_dict['USE'].shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:10:31.561512Z",
          "iopub.execute_input": "2024-10-13T14:10:31.561844Z",
          "iopub.status.idle": "2024-10-13T14:11:28.730078Z",
          "shell.execute_reply.started": "2024-10-13T14:10:31.561809Z",
          "shell.execute_reply": "2024-10-13T14:11:28.728991Z"
        },
        "trusted": true,
        "id": "rRLrNhlKBvG4",
        "outputId": "af87c232-47a9-4cb2-bb35-471b1561b344"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Generating USE embeddings...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "USE Embeddings: 100%|██████████| 5895/5895 [00:39<00:00, 147.42batch/s]\n",
          "output_type": "stream"
        },
        {
          "execution_count": 39,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(188636, 512)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generating RoBERTa embeddings...\")\n",
        "embeddings_dict['RoBERTa'] = get_roberta_embeddings(X_train)\n",
        "embeddings_dict['RoBERTa'].shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:11:28.731575Z",
          "iopub.execute_input": "2024-10-13T14:11:28.731892Z",
          "iopub.status.idle": "2024-10-13T14:18:09.480371Z",
          "shell.execute_reply.started": "2024-10-13T14:11:28.731859Z",
          "shell.execute_reply": "2024-10-13T14:18:09.47943Z"
        },
        "trusted": true,
        "id": "69HQWzZUBvG4",
        "outputId": "13ae5385-df43-4897-82a5-9aaf6d6d52fd",
        "colab": {
          "referenced_widgets": [
            "429a7397b74a41f89a44cf662be79f0b",
            "a9d37afb9c844717adab6a39b60a8a85",
            "c0c7eabfead94f358f7f82fa00e68af6",
            "ad2cde44a31342078384c78728b8b59c",
            "417439298efa425aaa8a5b80ce577b37",
            "c3263ec7031c446ea0da81277f912979"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Generating RoBERTa embeddings...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "429a7397b74a41f89a44cf662be79f0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9d37afb9c844717adab6a39b60a8a85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0c7eabfead94f358f7f82fa00e68af6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad2cde44a31342078384c78728b8b59c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "417439298efa425aaa8a5b80ce577b37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3263ec7031c446ea0da81277f912979"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nRoBERTa Embeddings: 100%|██████████| 5895/5895 [06:36<00:00, 14.85it/s]\n",
          "output_type": "stream"
        },
        {
          "execution_count": 40,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(188636, 768)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generating ALBERT embeddings...\")\n",
        "embeddings_dict['ALBERT'] = get_albert_embeddings(X_train)\n",
        "embeddings_dict['ALBERT'].shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:18:09.482074Z",
          "iopub.execute_input": "2024-10-13T14:18:09.482489Z",
          "iopub.status.idle": "2024-10-13T14:25:58.726697Z",
          "shell.execute_reply.started": "2024-10-13T14:18:09.482444Z",
          "shell.execute_reply": "2024-10-13T14:25:58.7256Z"
        },
        "trusted": true,
        "id": "w1pA5AjPBvG4",
        "outputId": "24031dec-ee09-48e0-81b5-f5c2c0c0e256",
        "colab": {
          "referenced_widgets": [
            "da0bceaeee9b413fbe4e8b0da8b321c1",
            "c19ecd9c2c404ac4bff488b645107953",
            "d0c51b830e8b486dbb0a04656e7dd64a",
            "05e4dc994c7a4aa3bd41e5661f630815",
            "da72939ca1b64dbea4fde8058f1673ab"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Generating ALBERT embeddings...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da0bceaeee9b413fbe4e8b0da8b321c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c19ecd9c2c404ac4bff488b645107953"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0c51b830e8b486dbb0a04656e7dd64a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05e4dc994c7a4aa3bd41e5661f630815"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da72939ca1b64dbea4fde8058f1673ab"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "ALBERT Embeddings: 100%|██████████| 5895/5895 [07:47<00:00, 12.62it/s]\n",
          "output_type": "stream"
        },
        {
          "execution_count": 41,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(188636, 768)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_embeddings_dict = {}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:25:58.728069Z",
          "iopub.execute_input": "2024-10-13T14:25:58.728443Z",
          "iopub.status.idle": "2024-10-13T14:25:58.73305Z",
          "shell.execute_reply.started": "2024-10-13T14:25:58.728405Z",
          "shell.execute_reply": "2024-10-13T14:25:58.732038Z"
        },
        "trusted": true,
        "id": "vgs8awVdBvG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SBERT\n",
        "print(\"Generating SBERT test embeddings...\")\n",
        "test_embeddings_dict['SBERT'] = get_sbert_embeddings(X_test)\n",
        "test_embeddings_dict['SBERT'].shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:25:58.734601Z",
          "iopub.execute_input": "2024-10-13T14:25:58.735281Z",
          "iopub.status.idle": "2024-10-13T14:26:12.813709Z",
          "shell.execute_reply.started": "2024-10-13T14:25:58.735232Z",
          "shell.execute_reply": "2024-10-13T14:26:12.812533Z"
        },
        "trusted": true,
        "id": "MXRXtSgfBvG4",
        "outputId": "9460e74a-bc37-48aa-d8b2-e57763f639ec",
        "colab": {
          "referenced_widgets": [
            "da219fc6fed3408a83e636d9dad509b8"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Generating SBERT test embeddings...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1474 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da219fc6fed3408a83e636d9dad509b8"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(47159, 384)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT CLS Token\n",
        "print(\"Generating BERT CLS test embeddings...\")\n",
        "test_embeddings_dict['BERT_CLS'] = get_bert_cls_embeddings(X_test)\n",
        "test_embeddings_dict['BERT_CLS'].shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:26:12.814902Z",
          "iopub.execute_input": "2024-10-13T14:26:12.815219Z",
          "iopub.status.idle": "2024-10-13T14:28:29.383961Z",
          "shell.execute_reply.started": "2024-10-13T14:26:12.815184Z",
          "shell.execute_reply": "2024-10-13T14:28:29.383039Z"
        },
        "trusted": true,
        "id": "9Inc-Km6BvG4",
        "outputId": "2fef6f14-6570-4ead-b132-b507f1417e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Generating BERT CLS test embeddings...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "BERT CLS Embeddings: 100%|██████████| 737/737 [02:16<00:00,  5.42it/s]\n",
          "output_type": "stream"
        },
        {
          "execution_count": 44,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(47159, 768)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USE\n",
        "print(\"Generating USE test embeddings...\")\n",
        "test_embeddings_dict['USE'] = get_use_embeddings(X_test)\n",
        "test_embeddings_dict['USE'].shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:28:29.385429Z",
          "iopub.execute_input": "2024-10-13T14:28:29.385753Z",
          "iopub.status.idle": "2024-10-13T14:28:47.506497Z",
          "shell.execute_reply.started": "2024-10-13T14:28:29.385718Z",
          "shell.execute_reply": "2024-10-13T14:28:47.505404Z"
        },
        "trusted": true,
        "id": "uJIq-6v3BvG5",
        "outputId": "e49eb0e0-428c-4302-fc85-f0100ada9655"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Generating USE test embeddings...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "USE Embeddings: 100%|██████████| 1474/1474 [00:10<00:00, 142.71batch/s]\n",
          "output_type": "stream"
        },
        {
          "execution_count": 45,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(47159, 512)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FastText\n",
        "print(\"Generating FastText test embeddings...\")\n",
        "test_embeddings_dict['FastText'] = get_fasttext_embeddings(X_test)\n",
        "test_embeddings_dict['FastText'].shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-13T14:28:47.507713Z",
          "iopub.execute_input": "2024-10-13T14:28:47.508047Z"
        },
        "trusted": true,
        "id": "vGvOE6TvBvG5",
        "outputId": "292ff7de-5f20-4399-fd14-e8a5c014b2fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Generating FastText test embeddings...\nLoading FastText model...\n[=-------------------------------------------------] 3.8% 36.9/958.4MB downloaded",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RoBERTa\n",
        "print(\"Generating RoBERTa test embeddings...\")\n",
        "test_embeddings_dict['RoBERTa'] = get_roberta_embeddings(X_test)\n",
        "test_embeddings_dict['RoBERTa'].shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "ChzwXa3WBvG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ALBERT\n",
        "print(\"Generating ALBERT test embeddings...\")\n",
        "test_embeddings_dict['ALBERT'] = get_albert_embeddings(X_test)\n",
        "test_embeddings_dict['ALBERT'].shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "GyLlt5S8BvG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model using pickle\n",
        "with open('embeddings_dict.pkl', 'wb') as f:\n",
        "  pickle.dump(embeddings_dict, f)\n",
        "with open('test_embeddings_dict.pkl', 'wb') as f:\n",
        "  pickle.dump(test_embeddings_dict, f)"
      ],
      "metadata": {
        "trusted": true,
        "id": "rLY-GsE_BvG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the manual features using pickle\n",
        "with open('X_train_manual_scaled.pkl', 'rb') as f:\n",
        "  X_train_manual_scaled = pickle.load(f)\n",
        "\n",
        "with open('X_test_manual_scaled(1).pkl', 'rb') as f:\n",
        "  X_test_manual_scaled = pickle.load(f)"
      ],
      "metadata": {
        "trusted": true,
        "id": "fZeLZOHtBvG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('embeddings_dict.pkl', 'rb') as f:\n",
        "  embeddings_dict=pickle.load( f)\n",
        "with open('test_embeddings_dict.pkl', 'rb') as f:\n",
        "  test_embeddings_dict=pickle.load(f)"
      ],
      "metadata": {
        "trusted": true,
        "id": "QwW9H9ekBvG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embeddings_dict.keys())"
      ],
      "metadata": {
        "trusted": true,
        "id": "EU5TrMF_BvG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
        "    # 'SVM_rbf': SVC(kernel='rbf', probability=True),\n",
        "     #'SVM_linear': SVC(kernel='linear', probability=True),\n",
        "    # 'SVM_poly': SVC(kernel='poly', probability=True),\n",
        "    # 'SVM_sigmoid': SVC(kernel='sigmoid', probability=True),\n",
        "    #'Decision Tree': DecisionTreeClassifier(),\n",
        "     #'Random Forest': RandomForestClassifier(n_estimators=100),\n",
        "    # 'Gradient Boosting': GradientBoostingClassifier(n_estimators=100),\n",
        "    # 'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
        "    # 'k-NN': KNeighborsClassifier(n_neighbors=5),\n",
        "    # 'Feed Forward NN': MLPClassifier(max_iter=1000),\n",
        "    # Add more neural network models as needed\n",
        "    # 'Convolutional NN': ...,\n",
        "    # 'RNN/LSTM': ...,\n",
        "    # 'Bidirectional LSTM': ...,\n",
        "    # 'TFBertForSequenceClassification': ...,\n",
        "}"
      ],
      "metadata": {
        "trusted": true,
        "id": "iY3N8_wPBvG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a list to store results\n",
        "results_list = []\n",
        "\n",
        "# Iterate over each embedding\n",
        "for embedding_name in embeddings_dict.keys():\n",
        "    print(f\"Processing embedding: {embedding_name}\")\n",
        "    X_train_sem_emb = embeddings_dict[embedding_name]\n",
        "    X_test_sem_emb = test_embeddings_dict[embedding_name]\n",
        "    # Concatenate training embeddings with manual features\n",
        "    X_train_emb = np.hstack((X_train_sem_emb, X_train_manual_scaled))\n",
        "\n",
        "    # Concatenate testing embeddings with manual features\n",
        "    X_test_emb = np.hstack((X_test_sem_emb, X_test_manual_scaled))\n",
        "    train_emb_shape = X_train_emb.shape\n",
        "    test_emb_shape = X_test_emb.shape\n",
        "    # Iterate over each model\n",
        "    for model_name, model in models.items():\n",
        "        print(f\"Training model: {model_name} with embedding: {embedding_name}\")\n",
        "        try:\n",
        "            model.fit(X_train_emb, y_train)\n",
        "            with open(f'{model_name}embedding{embedding_name}.pkl', 'wb') as f:\n",
        "              pickle.dump(model, f)\n",
        "            y_pred = model.predict(X_test_emb)\n",
        "\n",
        "            # Calculate metrics\n",
        "            acc = accuracy_score(y_test, y_pred)\n",
        "            f1 = f1_score(y_test, y_pred)\n",
        "            prec = precision_score(y_test, y_pred)\n",
        "            rec = recall_score(y_test, y_pred)\n",
        "\n",
        "            # Append results to the list\n",
        "            result = {\n",
        "                'Embedding': embedding_name,\n",
        "                'Train Emb Shape': train_emb_shape,\n",
        "                'Test Emb Shape': test_emb_shape,\n",
        "                'Model': model_name,\n",
        "                'Accuracy': acc,\n",
        "                'F1_Score': f1,\n",
        "                'Precision': prec,\n",
        "                'Recall': rec\n",
        "            }\n",
        "            print(result)\n",
        "            results_list.append(result)\n",
        "        except Exception as e:\n",
        "            print(f\"Error training {model_name} with {embedding_name}: {e}\")\n",
        "            results_list.append({\n",
        "                'Embedding': embedding_name,\n",
        "                'Model': model_name,\n",
        "                'Train Emb Shape': train_emb_shape,\n",
        "                'Test Emb Shape': test_emb_shape,\n",
        "                'Accuracy': None,\n",
        "                'F1_Score': None,\n",
        "                'Precision': None,\n",
        "                'Recall': None\n",
        "            })\n",
        "\n",
        "# Convert results list to DataFrame\n",
        "results = pd.DataFrame(results_list)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "AJR_DGZrBvG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Accuracy Matrix\n",
        "accuracy_matrix = results.pivot(index='Model', columns='Embedding', values='Accuracy')\n",
        "print(\"Accuracy Matrix:\")\n",
        "print(accuracy_matrix)\n",
        "\n",
        "# Similarly, you can create matrices for F1 Score, Precision, Recall\n",
        "f1_matrix = results.pivot(index='Model', columns='Embedding', values='F1_Score')\n",
        "precision_matrix = results.pivot(index='Model', columns='Embedding', values='Precision')\n",
        "recall_matrix = results.pivot(index='Model', columns='Embedding', values='Recall')\n",
        "\n",
        "# To save the results\n",
        "results.to_csv('model_embedding_results.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "u2hsZWr8BvG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ywY-V0a_BvG6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}